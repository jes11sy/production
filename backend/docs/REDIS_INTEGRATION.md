# üöÄ Redis –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

## –û–±–∑–æ—Ä

–î–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ Redis –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Å–∏—Å—Ç–µ–º—É —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞—è–≤–∫–∞–º–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å concurrent operations.

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- **Hit Rate**: 99%+ –¥–ª—è –º–µ—Ç—Ä–∏–∫
- **–£–ª—É—á—à–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏**: 10-20x –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–π —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
- **–°–Ω–∏–∂–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ –ë–î**: 90%+ –¥–ª—è —á–∞—Å—Ç–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **–£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–æ–∫**: 100% —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º concurrent operations

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
```bash
# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Redis
–ó–∞–ø–∏—Å—å 100 –∫–ª—é—á–µ–π: 0.031 —Å–µ–∫—É–Ω–¥—ã
–ß—Ç–µ–Ω–∏–µ 100 –∫–ª—é—á–µ–π: 0.015 —Å–µ–∫—É–Ω–¥—ã
Hit Rate: 99.02%
```

## üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

### –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
```
redis==5.0.1
redis[hiredis]==5.0.1
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Redis

```python
# app/core/cache.py
import redis.asyncio as redis
from typing import Optional, Any
import json
import pickle
from app.core.config import settings

class RedisCache:
    def __init__(self):
        self.redis_client: Optional[redis.Redis] = None
    
    async def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis"""
        self.redis_client = redis.from_url(
            settings.REDIS_URL,
            encoding="utf-8",
            decode_responses=False
        )
    
    async def disconnect(self):
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç Redis"""
        if self.redis_client:
            await self.redis_client.close()
    
    async def set(self, key: str, value: Any, ttl: int = 300):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ —Å TTL"""
        if self.redis_client:
            serialized_value = pickle.dumps(value)
            await self.redis_client.set(key, serialized_value, ex=ttl)
    
    async def get(self, key: str) -> Optional[Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ"""
        if self.redis_client:
            value = await self.redis_client.get(key)
            if value:
                return pickle.loads(value)
        return None
    
    async def delete(self, key: str):
        """–£–¥–∞–ª–∏—Ç—å –∫–ª—é—á"""
        if self.redis_client:
            await self.redis_client.delete(key)
    
    async def exists(self, key: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–∞"""
        if self.redis_client:
            return await self.redis_client.exists(key)
        return False

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
cache = RedisCache()
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ FastAPI

```python
# app/main.py
from app.core.cache import cache

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    await cache.connect()
    logger.info("Redis cache connected")

@app.on_event("shutdown")
async def shutdown_event():
    """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ"""
    await cache.disconnect()
    logger.info("Redis cache disconnected")
```

## üìà –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫

### –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫

```python
# app/monitoring/metrics.py
from app.core.cache import cache
import asyncio
from datetime import datetime, timedelta

class MetricsCollector:
    def __init__(self):
        self.cache_ttl = {
            'requests': 300,    # 5 –º–∏–Ω—É—Ç
            'transactions': 600, # 10 –º–∏–Ω—É—Ç
            'users': 300,       # 5 –º–∏–Ω—É—Ç
            'dashboard': 180    # 3 –º–∏–Ω—É—Ç—ã
        }
    
    async def collect_requests_metrics(self) -> dict:
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –∑–∞—è–≤–æ–∫ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "metrics:requests"
        
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫–µ—à–∞
        cached_data = await cache.get(cache_key)
        if cached_data:
            return cached_data
        
        # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î
        metrics = await self._fetch_requests_metrics()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫–µ—à
        await cache.set(cache_key, metrics, self.cache_ttl['requests'])
        
        return metrics
    
    async def collect_transactions_metrics(self) -> dict:
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "metrics:transactions"
        
        cached_data = await cache.get(cache_key)
        if cached_data:
            return cached_data
        
        metrics = await self._fetch_transactions_metrics()
        await cache.set(cache_key, metrics, self.cache_ttl['transactions'])
        
        return metrics
    
    async def collect_users_metrics(self) -> dict:
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = "metrics:users"
        
        cached_data = await cache.get(cache_key)
        if cached_data:
            return cached_data
        
        metrics = await self._fetch_users_metrics()
        await cache.set(cache_key, metrics, self.cache_ttl['users'])
        
        return metrics
    
    async def collect_dashboard_metrics(self) -> dict:
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞"""
        cache_key = "metrics:dashboard"
        
        cached_data = await cache.get(cache_key)
        if cached_data:
            return cached_data
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
        requests_task = self.collect_requests_metrics()
        transactions_task = self.collect_transactions_metrics()
        users_task = self.collect_users_metrics()
        
        requests_metrics, transactions_metrics, users_metrics = await asyncio.gather(
            requests_task,
            transactions_task,
            users_task
        )
        
        dashboard_metrics = {
            'requests': requests_metrics,
            'transactions': transactions_metrics,
            'users': users_metrics,
            'timestamp': datetime.now().isoformat()
        }
        
        await cache.set(cache_key, dashboard_metrics, self.cache_ttl['dashboard'])
        
        return dashboard_metrics
```

## üõ°Ô∏è Middleware –¥–ª—è HTTP –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è

```python
# app/monitoring/middleware.py
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware
from app.core.cache import cache
import hashlib
import json

class CacheMiddleware(BaseHTTPMiddleware):
    def __init__(self, app):
        super().__init__(app)
        self.cacheable_paths = ['/api/v1/metrics']
        self.cache_ttl = 60  # 1 –º–∏–Ω—É—Ç–∞ –¥–ª—è HTTP –∫–µ—à–∞
    
    async def dispatch(self, request: Request, call_next):
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω—É–∂–Ω–æ –ª–∏ –∫–µ—à–∏—Ä–æ–≤–∞—Ç—å
        if not any(request.url.path.startswith(path) for path in self.cacheable_paths):
            return await call_next(request)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫–µ—à–∞
        cache_key = self._generate_cache_key(request)
        
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫–µ—à–∞
        cached_response = await cache.get(cache_key)
        if cached_response:
            return Response(
                content=cached_response['content'],
                status_code=cached_response['status_code'],
                headers=cached_response['headers']
            )
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        response = await call_next(request)
        
        # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        if response.status_code == 200:
            response_data = {
                'content': response.body,
                'status_code': response.status_code,
                'headers': dict(response.headers)
            }
            await cache.set(cache_key, response_data, self.cache_ttl)
        
        return response
    
    def _generate_cache_key(self, request: Request) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫–µ—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ URL –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        key_data = f"{request.url.path}:{request.query_params}"
        return f"http_cache:{hashlib.md5(key_data.encode()).hexdigest()}"
```

## üîç –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ Redis

### –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```python
# app/monitoring/redis_metrics.py
from app.core.cache import cache
import time
from typing import Dict, Any

class RedisMetrics:
    def __init__(self):
        self.hit_count = 0
        self.miss_count = 0
        self.total_requests = 0
    
    async def get_redis_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ Redis"""
        if not cache.redis_client:
            return {}
        
        info = await cache.redis_client.info()
        return {
            'connected_clients': info.get('connected_clients', 0),
            'used_memory': info.get('used_memory', 0),
            'used_memory_human': info.get('used_memory_human', '0B'),
            'keyspace_hits': info.get('keyspace_hits', 0),
            'keyspace_misses': info.get('keyspace_misses', 0),
            'total_commands_processed': info.get('total_commands_processed', 0)
        }
    
    async def get_cache_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–µ—à–∞"""
        redis_info = await self.get_redis_info()
        
        hits = redis_info.get('keyspace_hits', 0)
        misses = redis_info.get('keyspace_misses', 0)
        total = hits + misses
        
        hit_rate = (hits / total * 100) if total > 0 else 0
        
        return {
            'hit_rate': round(hit_rate, 2),
            'hits': hits,
            'misses': misses,
            'total_requests': total,
            'memory_usage': redis_info.get('used_memory_human', '0B')
        }
    
    async def benchmark_cache(self, operations: int = 100) -> Dict[str, Any]:
        """–ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–µ—à–∞"""
        # –¢–µ—Å—Ç –∑–∞–ø–∏—Å–∏
        write_start = time.time()
        for i in range(operations):
            await cache.set(f"benchmark:write:{i}", f"value_{i}", 60)
        write_time = time.time() - write_start
        
        # –¢–µ—Å—Ç —á—Ç–µ–Ω–∏—è
        read_start = time.time()
        for i in range(operations):
            await cache.get(f"benchmark:write:{i}")
        read_time = time.time() - read_start
        
        # –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        for i in range(operations):
            await cache.delete(f"benchmark:write:{i}")
        
        return {
            'operations': operations,
            'write_time': round(write_time, 3),
            'read_time': round(read_time, 3),
            'writes_per_second': round(operations / write_time, 2),
            'reads_per_second': round(operations / read_time, 2)
        }

redis_metrics = RedisMetrics()
```

## üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```env
# Redis –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
REDIS_URL=redis://localhost:6379
REDIS_TTL_METRICS=300
REDIS_TTL_CACHE=600
REDIS_TTL_SESSIONS=3600

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
REDIS_MAX_CONNECTIONS=20
REDIS_RETRY_ON_TIMEOUT=true
REDIS_SOCKET_TIMEOUT=5
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ TTL

```python
# –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è TTL
TTL_SETTINGS = {
    'metrics_requests': 300,      # 5 –º–∏–Ω—É—Ç
    'metrics_transactions': 600,  # 10 –º–∏–Ω—É—Ç
    'metrics_users': 300,         # 5 –º–∏–Ω—É—Ç
    'dashboard_data': 180,        # 3 –º–∏–Ω—É—Ç—ã
    'http_cache': 60,             # 1 –º–∏–Ω—É—Ç–∞
    'session_data': 3600,         # 1 —á–∞—Å
    'user_preferences': 86400     # 24 —á–∞—Å–∞
}
```

## üö® –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ Redis —Å–µ—Ä–≤–µ—Ä–∞
redis-cli ping

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
python -c "
import asyncio
import redis.asyncio as redis

async def test():
    r = redis.from_url('redis://localhost:6379')
    result = await r.ping()
    print(f'Redis ping: {result}')
    await r.close()

asyncio.run(test())
"
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```bash
# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ Redis –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
redis-cli monitor

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Redis
redis-cli info stats

# –ü—Ä–æ—Å–º–æ—Ç—Ä –∫–ª—é—á–µ–π
redis-cli keys "metrics:*"
```

### –û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞

```bash
# –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫–ª—é—á–µ–π –º–µ—Ç—Ä–∏–∫
redis-cli eval "return redis.call('del', unpack(redis.call('keys', 'metrics:*')))" 0

# –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ–≥–æ –∫–µ—à–∞
redis-cli flushall
```

## üîß –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏

### 1. –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è

```python
# –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
async def get_data_with_cache(cache_key: str, fetch_func, ttl: int = 300):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
    # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫–µ—à–∞
    cached_data = await cache.get(cache_key)
    if cached_data:
        return cached_data
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    fresh_data = await fetch_func()
    
    # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
    await cache.set(cache_key, fresh_data, ttl)
    
    return fresh_data
```

### 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

```python
async def safe_cache_operation(operation):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–π —Å –∫–µ—à–µ–º"""
    try:
        return await operation()
    except redis.ConnectionError:
        logger.warning("Redis connection error, falling back to database")
        return None
    except Exception as e:
        logger.error(f"Cache operation failed: {e}")
        return None
```

### 3. –ò–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–µ—à–∞

```python
async def invalidate_related_cache(entity_type: str, entity_id: str):
    """–ò–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–≤—è–∑–∞–Ω–Ω–æ–≥–æ –∫–µ—à–∞"""
    patterns = {
        'request': ['metrics:requests', 'metrics:dashboard'],
        'transaction': ['metrics:transactions', 'metrics:dashboard'],
        'user': ['metrics:users', 'metrics:dashboard']
    }
    
    for pattern in patterns.get(entity_type, []):
        await cache.delete(pattern)
```

## üìä –ú–µ—Ç—Ä–∏–∫–∏ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞

### –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏

1. **Hit Rate**: –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø—Ä–æ—Å–æ–≤, –æ–±—Å–ª—É–∂–µ–Ω–Ω—ã—Ö –∏–∑ –∫–µ—à–∞
2. **Response Time**: –í—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
3. **Memory Usage**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ Redis
4. **Cache Efficiency**: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ —Ç–∏–ø–∞–º –¥–∞–Ω–Ω—ã—Ö

### –î–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫

```python
# –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ Redis
@app.get("/api/v1/admin/redis/stats")
async def get_redis_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Redis –¥–ª—è –∞–¥–º–∏–Ω –ø–∞–Ω–µ–ª–∏"""
    stats = await redis_metrics.get_cache_stats()
    info = await redis_metrics.get_redis_info()
    
    return {
        'cache_stats': stats,
        'redis_info': info,
        'timestamp': datetime.now().isoformat()
    }
```

## üöÄ –ü–ª–∞–Ω—ã —Ä–∞–∑–≤–∏—Ç–∏—è

### –ë–ª–∏–∂–∞–π—à–∏–µ —É–ª—É—á—à–µ–Ω–∏—è

1. **Distributed Caching**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Redis Cluster
2. **Advanced TTL**: –£–º–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ TTL –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
3. **Cache Warming**: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–µ—à–∞
4. **Compression**: –°–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

```python
# –ü—Ä–∏–º–µ—Ä –±—É–¥—É—â–∏—Ö —É–ª—É—á—à–µ–Ω–∏–π
class AdvancedCache(RedisCache):
    async def set_with_compression(self, key: str, value: Any, ttl: int = 300):
        """–°–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º"""
        import gzip
        serialized = pickle.dumps(value)
        compressed = gzip.compress(serialized)
        await self.redis_client.set(key, compressed, ex=ttl)
    
    async def get_with_decompression(self, key: str) -> Optional[Any]:
        """–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ —Å–∂–∞—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        import gzip
        compressed = await self.redis_client.get(key)
        if compressed:
            decompressed = gzip.decompress(compressed)
            return pickle.loads(decompressed)
        return None
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Redis Documentation](https://redis.io/documentation)
- [Redis Best Practices](https://redis.io/topics/memory-optimization)
- [FastAPI Caching](https://fastapi.tiangolo.com/advanced/custom-response/)
- [Async Redis Python](https://redis.readthedocs.io/en/stable/examples/asyncio_examples.html) 